# **Feature 1: Live View of Flights**





## **Data Pipeline**

__Ingestion Layer__:

   - A flight data stream is consumed from an external flight data provider, ingested into a stream-processing system 

Describe the tooling we'll use to ingest from streaming and how we will ingest into kafka

Describe message structure

Define schema, use schema manager? Prolly not necessary...

   - The system consumes messages every 5 seconds, where each message represents the current state of a flight (ID, location, altitude, airspeed, etc.).

2. **Processing Layer**:
   - Stream processors (e.g., Apache Flink or Apache Spark Streaming) aggregate and filter data based on the bounds of the home screen’s map view. For each client request, only flights within the specified geolocation are considered.
   - Flights are grouped by geolocation grids (e.g., quadtrees) to optimize spatial querying.

3. **Storage Layer**:
   - The live flight data is stored in an in-memory database (e.g., Redis or Memcached) to minimize access latency.
   - The system stores the current state of each flight keyed by flight ID.

#### 3.2 **Data Model**


- **Flight Table** (In-memory cache):
  ```
  flight_id (PK) | latitude | longitude | altitude | airspeed | last_updated
  ```

- **Geolocation Index** (In-memory grid):
  ```
  grid_id (PK) | flight_ids (List of flight IDs within this grid)
  ```



#### 3.3 **Storage Solution**

- **Tile38**: Chosen due to their ability to handle high-throughput and low-latency access. It provides fast in-memory storage and can handle bounding box queries natively. 


They provide efficient key-value storage for real-time data. Redis supports geospatial indexing and can serve as a cache for flight locations.




#### 3.4 **Query and API Design**



- **API Endpoint**: `GET /api/flights?bounds=<lat1,long1,lat2,long2>`
  - **Request**: The client provides the bounds of the map.
  - **Response**: A list of flights within the bounds, including flight ID, location, altitude, and airspeed.
  
- **Query Execution**:
  - Geolocation grids allow for efficient querying. When a request is made, the API queries Redis for flights in the specific geolocation grid, retrieves their data, and serves the response.








### GEOTILING 


To set up a geotiling system that efficiently displays all active flights in a specified area at any zoom level, we need to design a system that can quickly ingest and process real-time aircraft position updates and serve the data based on geographic location. The system must handle large-scale data for global flights while providing low-latency queries for clients at various zoom levels. Here's how I would approach it:

### **1. Data Ingestion and Geospatial Encoding**
We are receiving continuous position updates for aircraft globally, likely every few seconds. To efficiently handle this data, the system should:

- **Ingest Aircraft Data**: Each aircraft provides a stream of updates including aircraft ID, latitude, longitude, altitude, and metadata (flight number, airline, etc.).
- **Geohashing**: For each update, use a **geohash** or **quadkey** to convert the aircraft's latitude and longitude into a geospatial tile coordinate. A geohash encodes geographic locations into a compact string, where the precision of the string depends on the number of characters (similar to zoom levels in a map).
  - For example, a shorter geohash represents a larger area (low zoom level), while a longer geohash represents a smaller area (high zoom level).

### **2. Tiling System Design**
The tiling system must support zoom levels and geographic queries at any scale. Here’s how we can design the geotiling structure:

- **Quadtrees**: The Earth is divided into a hierarchical structure of tiles, where each tile is subdivided into four smaller tiles as zoom levels increase. This gives us an efficient way to organize and retrieve flight data at different resolutions.
  - **Tile Identifier (Tile ID)**: Each tile at a specific zoom level is identified by an (X, Y, Z) coordinate, where X and Y represent the position of the tile, and Z represents the zoom level.
  - **Zoom Level**: Zoom level 0 might cover the entire globe in one tile, and increasing the zoom level (e.g., Z=1, Z=2) will subdivide the tiles into increasingly smaller sections.

- **Data Storage for Tiles**:
  - For each tile at each zoom level, we store the flight data for the flights currently within that tile. This could be implemented using a spatial index such as **R-tree** or **QuadTree**, which supports efficient spatial querying.
  - Alternatively, we can store data in a **key-value store** like Redis, where the key is the tile identifier (geohash or quadkey) and the value is a list of active flights within that tile.

### **3. Updating the Tile Data with Flight Position Updates**
Whenever an aircraft provides a position update, the system must:
- **Calculate the Geohash**: Convert the latitude and longitude of the aircraft into a geohash or tile identifier (depending on the precision needed for the zoom level).
- **Update the Correct Tile**: The flight is added to the list of active flights in the corresponding tile. If the aircraft moves out of a tile, remove it from the previous tile and add it to the new one.
  - **In-memory Cache (Redis)**: Use an in-memory key-value store (e.g., Redis) to store the current list of flights for each tile. This provides fast read and write access for real-time updates.

### **4. Efficient Querying for Map Display**
When a user queries the map at a specific zoom level, the system needs to retrieve the relevant flights within the visible tiles. Here’s how we handle the queries:

- **Identify Visible Tiles**: Based on the map bounds (latitude/longitude range) and the zoom level, determine which tiles are visible in the user's view.
  - For example, at zoom level Z=4, you might be displaying a grid of tiles over a small region (e.g., a city).
  - Calculate the tile coordinates (X, Y, Z) for the bounding box of the view area.

- **Query the Relevant Tiles**: Fetch the flight data for each tile within the view. Since the flight data for each tile is stored in Redis or a similar store, retrieving the flight list for each tile is fast.
  - **Redis Example**:
    ```bash
    GET flights_in_tile:{geohash}  # Returns the list of flights in the tile
    ```
  - Aggregate the data across all visible tiles and return it to the client.

- **Zoom Level Optimization**: Depending on the zoom level, the system can dynamically adjust the precision of geohashes or quadkeys.
  - At low zoom levels (zoomed out), use fewer characters of the geohash, resulting in larger tiles with many flights.
  - At high zoom levels (zoomed in), use more characters to generate smaller tiles, resulting in fewer flights per tile.

### **5. Handling Zoom Level Transitions**
As the user zooms in and out of the map:
- **Merge Data at Low Zoom Levels**: When zoomed out, the system should group flights that are in nearby tiles together. This can be done by aggregating data from multiple tiles or by using a coarser geohash.
  - Example: At zoom level Z=1, flights in neighboring tiles (e.g., geohash `abcd`, `abce`, `abcf`) might be displayed together to avoid cluttering the map.

- **Detail at High Zoom Levels**: At higher zoom levels, the system retrieves more precise tile data (smaller tiles) and displays more detailed information, such as individual flight paths or metadata about each flight.

### **6. Data Partitioning and Sharding for Scalability**
Given the large scale of flight data, the system needs to scale horizontally:
- **Sharding by Tile Key**: Partition the data by geohash or tile key, with each shard handling a specific geographic region. This allows the system to distribute the load across multiple servers.
  - Redis or another distributed cache can be used to shard the data across multiple nodes.
  
- **Load Balancing**: The queries can be load-balanced across multiple servers based on geographic region or user location, ensuring high availability and minimizing latency.

### **7. Summary of the System Design**
1. **Data Ingestion**: Aircraft position updates are ingested and geohashed.
2. **Tiling System**: A quadtree structure is used to divide the world into tiles at different zoom levels, each tile storing the current flights within it.
3. **Storage**: Store active flights in tiles using Redis or another in-memory cache, keyed by geohash or quadkey.
4. **Querying**: When a user views the map, visible tiles are identified and queried for flight data.
5. **Scalability**: Use sharding and distributed storage to handle the global scale of flight data, ensuring fast responses and low latency.

### **Technologies**:
- **Redis**: For fast storage and retrieval of tile data.
- **Geohashing/Quadtrees**: For efficient spatial indexing.
- **Apache Kafka**: For ingesting real-time flight position updates.
- **Load Balancers**: To distribute queries across servers.

By combining real-time geospatial indexing with efficient data storage and querying, this system can handle large-scale flight tracking and provide users with quick, accurate map updates at any zoom level.